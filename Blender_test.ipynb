{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tsururu.dataset import IndexSlicer, Pipeline, TSDataset\n",
    "from tsururu.models import CatBoostRegressor_CV, MeanBlender, BestModel, ClassicBlender\n",
    "from tsururu.strategies import (\n",
    "    DirectStrategy,\n",
    "    FlatWideMIMOStrategy,\n",
    "    MIMOStrategy,\n",
    "    RecursiveStrategy,\n",
    ")\n",
    "from tsururu.transformers import (\n",
    "    DateSeasonsGenerator,\n",
    "    DifferenceNormalizer,\n",
    "    LagTransformer,\n",
    "    LastKnownNormalizer,\n",
    "    SequentialTransformer,\n",
    "    StandardScalerTransformer,\n",
    "    TargetGenerator,\n",
    "    UnionTransformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(\n",
    "    cv: int,\n",
    "    regime: str,\n",
    "    y_true: Optional[List[np.ndarray]] = None,\n",
    "    y_pred: Optional[List[np.ndarray]] = None,\n",
    "    ids: Optional[List[Union[float, str]]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    def _get_fold_value(\n",
    "        value: Optional[Union[float, np.ndarray]], idx: int\n",
    "    ) -> List[Optional[Union[float, np.ndarray]]]:\n",
    "        if value is None:\n",
    "            return [None]\n",
    "        if isinstance(value[idx], float):\n",
    "            return value[idx]\n",
    "        if isinstance(value[idx], np.ndarray):\n",
    "            return value[idx].reshape(-1)\n",
    "        raise TypeError(f\"Unexpected value type. Value: {value}\")\n",
    "\n",
    "    df_res_dict = {}\n",
    "\n",
    "    for idx_fold in range(cv):\n",
    "        # Fill df_res_dict\n",
    "        for name, value in [(\"y_true\", y_true), (\"y_pred\", y_pred)]:\n",
    "            df_res_dict[f\"{name}_{idx_fold+1}\"] = _get_fold_value(\n",
    "                value, idx_fold\n",
    "            )\n",
    "        if regime != \"local\":\n",
    "            df_res_dict[f\"id_{idx_fold+1}\"] = _get_fold_value(ids, idx_fold)\n",
    "\n",
    "    # Save datasets to specified directory\n",
    "    df_res = pd.DataFrame(df_res_dict)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several main objects to look out for when working with the library:\n",
    "1) `TSDataset`.\n",
    "2) `Pipeline` and `Transformers`\n",
    "3) `Strategy`.\n",
    "4) `Model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is needed to store data and meta-information about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialise it is necessary to submit the data in `pd.DataFrame` format and define some meta-information about roles that necessary for solving the task of time series forecasting: `id`, `date`, `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"datasets/global/ettm1.csv\"\n",
    "\n",
    "dataset_params = {\n",
    "    \"target\": {\n",
    "        \"columns\": [\"value\"],\n",
    "        \"type\": \"continious\",\n",
    "    },\n",
    "    \"date\": {\n",
    "        \"columns\": [\"date\"],\n",
    "        \"type\": \"datetime\",\n",
    "    },\n",
    "    \"id\": {\n",
    "        \"columns\": [\"id\"],\n",
    "        \"type\": \"categorical\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset = TSDataset(\n",
    "    data=pd.read_csv(df_path),\n",
    "    columns_params=dataset_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What kind of transformers are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special attention should be paid to the `Transformer` class: the elements of the pipeline that are responsible for transforming the values of a series and generating features. `Pipeline` class is a wrapper over transformers which is needed to provide some additional methods and functions above them.\n",
    "\n",
    "There are two types of transformers that are used to collect pipelines:\n",
    "- `Union` transformers;\n",
    "- `Sequential` transformers.\n",
    "\n",
    "Below is a list of available Transformers: \n",
    "- `StandardScalerTransformer` *(Series4Series)*.\n",
    "- `DifferenceNormalizer` *(Series4Series)*: subtract the previous value or divide by it.\n",
    "- `LastKnownNormalizer` *(Features4Features)*: normalize all lags by the last known one: divide by it or subtract.\n",
    "\n",
    "This three transformers provide flags `transform_features` / `transform_target`, that allow you to manipulate traits and targets separately and get different results from them.\n",
    "\n",
    "Besides, __DifferenceNormalizer__ and __LastKnownNormalizer__ can be applied in two regimes: `delta` and `ratio`: in the first case, normalisation means subtracting the target value from the current value, and in the second, dividing by it.\n",
    "\n",
    "- `LabelEncodingTransformer` and `OneHotEncodingTransformer` *(Series4Series)* - encoders for categorical features.\n",
    "- `TimeToNumGenerator` and `DateSeasonsGenerator` *(Series4Series)* - generator for seasonal features by dates.\n",
    "- `LagTransformer` *(Series4Features) - generator for lags. \n",
    "\n",
    "__!!!The lag transformer must necessarily be present in the sequential transformer, otherwise the features will not be generated.!!!__\n",
    "\n",
    "Finally, to generate targets, you need to use `TargetGenerator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers must be assembled in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __SeriesToSeries__ transformers should come first, followed by the LagTransformer and TargetGenerator (__SeriesToFeatures__), and then the __FeaturesToFeatures__ transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to build a Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are two ways to build a pipline from transformers: initialise the transformers of interest by hand or use a config in the form of a dictionary. Let's look at both ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScalerTransformer(\n",
    "    transform_features=True,\n",
    "    transform_target=True\n",
    ")\n",
    "\n",
    "lag = LagTransformer(lags=3)\n",
    "date_lag = LagTransformer(lags=3)\n",
    "id_lag = LagTransformer(lags=1)\n",
    "\n",
    "target_generator = TargetGenerator()\n",
    "\n",
    "date_seasons = DateSeasonsGenerator(\n",
    "    seasonalities=[\"doy\", \"m\", \"wd\"],\n",
    "    from_target_date=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_1 = UnionTransformer(transformers_list=[lag, target_generator])\n",
    "\n",
    "seq_1 = SequentialTransformer(transformers_list=[standard_scaler, union_1], input_features=[\"value\"])\n",
    "seq_2 = SequentialTransformer(transformers_list=[date_seasons, date_lag], input_features=[\"date\"])\n",
    "seq_3 = SequentialTransformer(transformers_list=[id_lag], input_features=[\"id\"])\n",
    "\n",
    "union = UnionTransformer(transformers_list=[seq_1, seq_2, seq_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline(union, multivariate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformers': <tsururu.transformers.base.UnionTransformer at 0x1ae6deba750>,\n",
       " 'multivariate': False,\n",
       " 'is_fitted': False,\n",
       " 'strategy_name': None,\n",
       " 'output_features': None,\n",
       " 'y_original_shape': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    \"target\": {\n",
    "        \"columns\": [\"value\"],\n",
    "        \"features\": {\n",
    "            \"StandardScalerTransformer\":\n",
    "                {\n",
    "                    \"transform_target\": True, \n",
    "                    \"transform_features\": True\n",
    "                },\n",
    "            \"LagTransformer\": {\"lags\": 7},\n",
    "        },\n",
    "    },\n",
    "    \"date\": {\n",
    "        \"columns\": [\"date\"],\n",
    "        \"features\": {\n",
    "            \"DateSeasonsGenerator\": {\n",
    "                # Use seasonality features from the date column as \n",
    "                # features with datetime lags\n",
    "                # Possible values: [\n",
    "                #    \"y\": year, \"m\": month, \"d\": day, \n",
    "                #    \"wd\": weekday, \"doy\": dayofyear,\n",
    "                #    \"hour\": hour, \"min\": minute, \"sec\": second, \n",
    "                #    \"ms\": microsecond,  \"ns\": nanosecond\n",
    "                # ]\n",
    "                \"seasonalities\": ['doy', 'm', 'wd'], \n",
    "                # Use date from target point to make datetime features\n",
    "                \"from_target_date\": True,\n",
    "            },\n",
    "            \"LagTransformer\": {\"lags\": 3}\n",
    "        },\n",
    "    },\n",
    "    \"id\": {\n",
    "        \"columns\": [\"id\"],\n",
    "        \"features\": {\n",
    "            \"LagTransformer\": {\"lags\": 1},\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_dict(pipeline_params, multivariate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can I use exogenous variables in the pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Exogenous variables can also be specified here. Just include them in your pipeline.\n",
    "\n",
    "However, their operation is currently tested only for the `MIMOStrategy` in global-modelling. For other strategies support of additional variables is under development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params[\"exog_group_1\"] = {\n",
    "     \"columns\": [\"value\"],\n",
    "     \"features\": {\n",
    "         \"StandardScalerTransformer\":\n",
    "             {\n",
    "                 \"transform_target\": False, \n",
    "                 \"transform_features\": True\n",
    "             },\n",
    "         \"LagTransformer\": {\"lags\": 7},\n",
    "     },\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make sure you have the transform_target = False flag for exogenous features!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is separate from the strategy. Any model can be run in any strategy if it supports this input and output format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the easiest options – is to use GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model parameters\n",
    "model_params = {\n",
    "    \"loss_function\": \"MultiRMSE\",\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"verbose\": 500,\n",
    "}\n",
    "\n",
    "# Configure the validation parameters\n",
    "validation_params = {\n",
    "    \"type\": 'KFold',\n",
    "    \"n_splits\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor_CV(validation_params, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _Recursive:_ \n",
    "    - one model for all points of the forecast horizon;\n",
    "    - *training*: the model is trained to predict one point ahead;\n",
    "    - *prediction*: a prediction is iteratively made one point ahead, and then this prediction is used to further shape the features in the test data. \n",
    "- _Recursive-reduced:_\n",
    "    - one model for all points in the prediction horizon;\n",
    "    - *training*: the model is trained to predict one point ahead;\n",
    "    - *prediction*: features are generated for all test observations at once, unavailable values are replaced by NaN.\n",
    "- _Direct:_ \n",
    "    - individual models for each point in the prediction horizon. \n",
    "- _MultiOutput (MIMO - Multi-input-multi-output):_\n",
    "    - one model that learns to predict the entire prediction horizon. \n",
    "- _FlatWideMIMO:_.\n",
    "    - mixture of Direct and MIMO, fit one model, but uses deployed over horizon Direct's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 3\n",
    "history = 7\n",
    "step = 1\n",
    "\n",
    "strategy = RecursiveStrategy(horizon, history, step, model, pipeline)\n",
    "strategy2 = DirectStrategy(horizon, history, step, model, pipeline)\n",
    "\n",
    "strtgs = [strategy, strategy2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blender test\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "blender = ClassicBlender(strtgs, RandomForestRegressor(max_depth=30), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n",
      "                      date  id  value\n",
      "0      2016-07-01 00:00:00   0  5.827\n",
      "1      2016-07-01 00:15:00   0  5.760\n",
      "2      2016-07-01 00:30:00   0  5.760\n",
      "3      2016-07-01 00:45:00   0  5.760\n",
      "4      2016-07-01 01:00:00   0  5.693\n",
      "...                    ...  ..    ...\n",
      "432011 2016-11-23 02:45:00   6  2.884\n",
      "432012 2016-11-23 03:00:00   6  2.955\n",
      "432013 2016-11-23 03:15:00   6  3.236\n",
      "432014 2016-11-23 03:30:00   6  3.447\n",
      "432015 2016-11-23 03:45:00   6  3.447\n",
      "\n",
      "[97552 rows x 3 columns]\n",
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n",
      "                      date  id   value\n",
      "13936  2016-11-23 04:00:00   0  10.985\n",
      "13937  2016-11-23 04:15:00   0  12.659\n",
      "13938  2016-11-23 04:30:00   0  11.788\n",
      "13939  2016-11-23 04:45:00   0  11.052\n",
      "13940  2016-11-23 05:00:00   0  12.525\n",
      "...                    ...  ..     ...\n",
      "487755 2018-06-26 18:45:00   6   9.567\n",
      "487756 2018-06-26 19:00:00   6   9.567\n",
      "487757 2018-06-26 19:15:00   6   9.426\n",
      "487758 2018-06-26 19:30:00   6   9.426\n",
      "487759 2018-06-26 19:45:00   6   9.778\n",
      "\n",
      "[390208 rows x 3 columns]\n",
      "0:\tlearn: 0.9703929\ttest: 0.9780205\tbest: 0.9780205 (0)\ttotal: 161ms\tremaining: 2m 41s\n",
      "500:\tlearn: 0.2463630\ttest: 0.2474082\tbest: 0.2474082 (500)\ttotal: 1.29s\tremaining: 1.28s\n",
      "999:\tlearn: 0.2385687\ttest: 0.2458558\tbest: 0.2458557 (998)\ttotal: 2.38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2458556524\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Fold 0:\n",
      "MultiRMSE: 0.24585565239683665\n",
      "0:\tlearn: 0.9777228\ttest: 0.9702035\tbest: 0.9702035 (0)\ttotal: 5.01ms\tremaining: 5.01s\n",
      "500:\tlearn: 0.2415191\ttest: 0.2520980\tbest: 0.2520980 (500)\ttotal: 1.13s\tremaining: 1.12s\n",
      "999:\tlearn: 0.2334088\ttest: 0.2503813\tbest: 0.2503760 (997)\ttotal: 2.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2503759554\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n",
      "Fold 1:\n",
      "MultiRMSE: 0.2503759554390058\n",
      "Mean MultiRMSE: 0.2481\n",
      "Std: 0.0023\n",
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n",
      "   id                date      value\n",
      "0   0 2016-11-23 04:00:00  12.194992\n",
      "1   0 2016-11-23 04:15:00  12.253615\n",
      "2   0 2016-11-23 04:30:00  12.221137\n",
      "3   1 2016-11-23 04:00:00   5.291224\n",
      "4   1 2016-11-23 04:15:00   5.288779\n",
      "5   1 2016-11-23 04:30:00   5.228797\n",
      "6   2 2016-11-23 04:00:00   1.378553\n",
      "7   2 2016-11-23 04:15:00   1.422188\n",
      "8   2 2016-11-23 04:30:00   1.481652\n",
      "9   3 2016-11-23 04:00:00   0.424517\n",
      "10  3 2016-11-23 04:15:00   0.420088\n",
      "11  3 2016-11-23 04:30:00   0.407961\n",
      "12  4 2016-11-23 04:00:00  10.607423\n",
      "13  4 2016-11-23 04:15:00  10.599372\n",
      "14  4 2016-11-23 04:30:00  10.580772\n",
      "15  5 2016-11-23 04:00:00   3.951461\n",
      "16  5 2016-11-23 04:15:00   3.834913\n",
      "17  5 2016-11-23 04:30:00   3.747511\n",
      "18  6 2016-11-23 04:00:00   2.670025\n",
      "19  6 2016-11-23 04:15:00   2.684009\n",
      "20  6 2016-11-23 04:30:00   2.641023\n",
      "True values shape: (21,)\n",
      "[10.98499966 12.6590004  11.78800011  5.29099989  5.62599993  4.21999979\n",
      "  1.34000003  1.523       1.523       0.426       0.45699999  0.426\n",
      " 10.05599976 10.7670002  10.30500031  4.30000019  3.6960001   3.58899999\n",
      "  2.81399989  2.6730001   3.51699996]\n",
      "0:\tlearn: 0.9703929\ttest: 0.9780205\tbest: 0.9780205 (0)\ttotal: 6ms\tremaining: 5.99s\n",
      "500:\tlearn: 0.2463630\ttest: 0.2474082\tbest: 0.2474082 (500)\ttotal: 1.11s\tremaining: 1.11s\n",
      "999:\tlearn: 0.2385687\ttest: 0.2458558\tbest: 0.2458557 (998)\ttotal: 2.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2458556524\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Fold 0:\n",
      "MultiRMSE: 0.24585565239683665\n",
      "0:\tlearn: 0.9777228\ttest: 0.9702035\tbest: 0.9702035 (0)\ttotal: 5.04ms\tremaining: 5.04s\n",
      "500:\tlearn: 0.2415191\ttest: 0.2520980\tbest: 0.2520980 (500)\ttotal: 1.1s\tremaining: 1.1s\n",
      "999:\tlearn: 0.2334088\ttest: 0.2503813\tbest: 0.2503760 (997)\ttotal: 2.19s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2503759554\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n",
      "Fold 1:\n",
      "MultiRMSE: 0.2503759554390058\n",
      "Mean MultiRMSE: 0.2481\n",
      "Std: 0.0023\n",
      "0:\tlearn: 0.9721735\ttest: 0.9779304\tbest: 0.9779304 (0)\ttotal: 12ms\tremaining: 12s\n",
      "500:\tlearn: 0.3019155\ttest: 0.3032628\tbest: 0.3032628 (500)\ttotal: 1.14s\tremaining: 1.14s\n",
      "999:\tlearn: 0.2921035\ttest: 0.3003248\tbest: 0.3003239 (998)\ttotal: 2.24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3003238544\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Fold 0:\n",
      "MultiRMSE: 0.3003238543740736\n",
      "0:\tlearn: 0.9775241\ttest: 0.9718479\tbest: 0.9718479 (0)\ttotal: 5.26ms\tremaining: 5.25s\n",
      "500:\tlearn: 0.2952898\ttest: 0.3076260\tbest: 0.3076260 (500)\ttotal: 1.13s\tremaining: 1.13s\n",
      "999:\tlearn: 0.2856740\ttest: 0.3052232\tbest: 0.3052232 (999)\ttotal: 2.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3052231917\n",
      "bestIteration = 999\n",
      "\n",
      "Fold 1:\n",
      "MultiRMSE: 0.3052231917326785\n",
      "Mean MultiRMSE: 0.3028\n",
      "Std: 0.0024\n",
      "0:\tlearn: 0.9712839\ttest: 0.9804208\tbest: 0.9804208 (0)\ttotal: 4.55ms\tremaining: 4.54s\n",
      "500:\tlearn: 0.3393643\ttest: 0.3462554\tbest: 0.3462554 (500)\ttotal: 1.1s\tremaining: 1.1s\n",
      "999:\tlearn: 0.3280719\ttest: 0.3426870\tbest: 0.3426870 (999)\ttotal: 2.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3426869646\n",
      "bestIteration = 999\n",
      "\n",
      "Fold 0:\n",
      "MultiRMSE: 0.34268696462106146\n",
      "0:\tlearn: 0.9802140\ttest: 0.9711586\tbest: 0.9711586 (0)\ttotal: 3.84ms\tremaining: 3.84s\n",
      "500:\tlearn: 0.3390990\ttest: 0.3465693\tbest: 0.3465693 (500)\ttotal: 1.12s\tremaining: 1.12s\n",
      "999:\tlearn: 0.3277945\ttest: 0.3426588\tbest: 0.3426588 (999)\ttotal: 2.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3426587904\n",
      "bestIteration = 999\n",
      "\n",
      "Fold 1:\n",
      "MultiRMSE: 0.3426587904258353\n",
      "Mean MultiRMSE: 0.3427\n",
      "Std: 0.0\n",
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n",
      "   id                date      value\n",
      "0   0 2016-11-23 04:00:00  12.194992\n",
      "1   0 2016-11-23 04:15:00   12.28053\n",
      "2   0 2016-11-23 04:30:00  12.323502\n",
      "3   1 2016-11-23 04:00:00   5.291224\n",
      "4   1 2016-11-23 04:15:00   5.238816\n",
      "5   1 2016-11-23 04:30:00   5.126668\n",
      "6   2 2016-11-23 04:00:00   1.378553\n",
      "7   2 2016-11-23 04:15:00   1.445462\n",
      "8   2 2016-11-23 04:30:00   1.511752\n",
      "9   3 2016-11-23 04:00:00   0.424517\n",
      "10  3 2016-11-23 04:15:00   0.419217\n",
      "11  3 2016-11-23 04:30:00   0.419409\n",
      "12  4 2016-11-23 04:00:00  10.607423\n",
      "13  4 2016-11-23 04:15:00  10.567405\n",
      "14  4 2016-11-23 04:30:00  10.410642\n",
      "15  5 2016-11-23 04:00:00   3.951461\n",
      "16  5 2016-11-23 04:15:00   3.820322\n",
      "17  5 2016-11-23 04:30:00   3.685236\n",
      "18  6 2016-11-23 04:00:00   2.670025\n",
      "19  6 2016-11-23 04:15:00   2.972499\n",
      "20  6 2016-11-23 04:30:00   3.208047\n",
      "Meta features: [[12.194992039446522 12.194992039446522]\n",
      " [12.253614723102856 12.280529930994811]\n",
      " [12.221136618338893 12.323501984211305]\n",
      " [5.2912242857137795 5.2912242857137795]\n",
      " [5.2887787389857746 5.238816099727171]\n",
      " [5.228797032992498 5.126667950053275]\n",
      " [1.3785534805270607 1.3785534805270607]\n",
      " [1.4221877203805648 1.4454624054536924]\n",
      " [1.481652021238114 1.5117519936786323]\n",
      " [0.4245169216411192 0.4245169216411192]\n",
      " [0.4200882405325528 0.4192167431598165]\n",
      " [0.4079609534391348 0.41940864813442685]\n",
      " [10.6074228814259 10.6074228814259]\n",
      " [10.599371815947794 10.567405488613977]\n",
      " [10.580772310784837 10.410642144561113]\n",
      " [3.9514613679580437 3.9514613679580437]\n",
      " [3.8349127090336155 3.820321787078562]\n",
      " [3.7475107737829596 3.6852360520928276]\n",
      " [2.6700249749213008 2.6700249749213008]\n",
      " [2.6840090420141784 2.972499006528313]\n",
      " [2.64102327602064 3.2080468216413465]]\n",
      "Meta targets: [10.98499966 12.6590004  11.78800011  5.29099989  5.62599993  4.21999979\n",
      "  1.34000003  1.523       1.523       0.426       0.45699999  0.426\n",
      " 10.05599976 10.7670002  10.30500031  4.30000019  3.6960001   3.58899999\n",
      "  2.81399989  2.6730001   3.51699996]\n",
      "Meta-model training complete.\n"
     ]
    }
   ],
   "source": [
    "fitted_blender = blender.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n",
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "for id, group in dataset.data.groupby('id'):\n",
    "    split_index = int(len(group) * 0.8)\n",
    "    train_data.append(group.iloc[:split_index])\n",
    "    val_data.append(group.iloc[split_index:])\n",
    "        \n",
    "train_data = pd.concat(train_data)\n",
    "val_data = pd.concat(val_data)\n",
    "\n",
    "train_dataset = TSDataset(train_data, dataset.columns_params, dataset.delta)\n",
    "val_dataset = TSDataset(val_data, dataset.columns_params, dataset.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 00:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 00:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55739</th>\n",
       "      <td>2018-02-01 14:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55740</th>\n",
       "      <td>2018-02-01 15:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55741</th>\n",
       "      <td>2018-02-01 15:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55742</th>\n",
       "      <td>2018-02-01 15:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55743</th>\n",
       "      <td>2018-02-01 15:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55744 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  id  value\n",
       "0     2016-07-01 00:00:00   0  5.827\n",
       "1     2016-07-01 00:15:00   0  5.760\n",
       "2     2016-07-01 00:30:00   0  5.760\n",
       "3     2016-07-01 00:45:00   0  5.760\n",
       "4     2016-07-01 01:00:00   0  5.693\n",
       "...                   ...  ..    ...\n",
       "55739 2018-02-01 14:45:00   0  4.957\n",
       "55740 2018-02-01 15:00:00   0  5.961\n",
       "55741 2018-02-01 15:15:00   0 -1.474\n",
       "55742 2018-02-01 15:30:00   0 -2.143\n",
       "55743 2018-02-01 15:45:00   0 -0.402\n",
       "\n",
       "[55744 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data[train_dataset.data.id==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55744</th>\n",
       "      <td>2018-02-01 16:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55745</th>\n",
       "      <td>2018-02-01 16:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55746</th>\n",
       "      <td>2018-02-01 16:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55747</th>\n",
       "      <td>2018-02-01 16:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55748</th>\n",
       "      <td>2018-02-01 17:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>13.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69675</th>\n",
       "      <td>2018-06-26 18:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69676</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69677</th>\n",
       "      <td>2018-06-26 19:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69678</th>\n",
       "      <td>2018-06-26 19:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69679</th>\n",
       "      <td>2018-06-26 19:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13936 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  id   value\n",
       "55744 2018-02-01 16:00:00   0   3.684\n",
       "55745 2018-02-01 16:15:00   0   5.693\n",
       "55746 2018-02-01 16:30:00   0  11.721\n",
       "55747 2018-02-01 16:45:00   0  11.922\n",
       "55748 2018-02-01 17:00:00   0  13.329\n",
       "...                   ...  ..     ...\n",
       "69675 2018-06-26 18:45:00   0   9.310\n",
       "69676 2018-06-26 19:00:00   0  10.114\n",
       "69677 2018-06-26 19:15:00   0  10.784\n",
       "69678 2018-06-26 19:30:00   0  11.655\n",
       "69679 2018-06-26 19:45:00   0  12.994\n",
       "\n",
       "[13936 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.data[val_dataset.data.id==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9745768\ttest: 0.9727270\tbest: 0.9727270 (0)\ttotal: 9.51ms\tremaining: 9.5s\n",
      "500:\tlearn: 0.2140805\ttest: 0.2164315\tbest: 0.2164315 (500)\ttotal: 3.23s\tremaining: 3.22s\n",
      "999:\tlearn: 0.2104164\ttest: 0.2147511\tbest: 0.2147511 (999)\ttotal: 6.43s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2147510735\n",
      "bestIteration = 999\n",
      "\n",
      "Fold 0:\n",
      "MultiRMSE: 0.21475107347532177\n",
      "0:\tlearn: 0.9727297\ttest: 0.9745896\tbest: 0.9745896 (0)\ttotal: 8.82ms\tremaining: 8.82s\n",
      "500:\tlearn: 0.2141088\ttest: 0.2163332\tbest: 0.2163332 (500)\ttotal: 3.22s\tremaining: 3.21s\n",
      "999:\tlearn: 0.2101859\ttest: 0.2146711\tbest: 0.2146711 (999)\ttotal: 6.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2146710724\n",
      "bestIteration = 999\n",
      "\n",
      "Fold 1:\n",
      "MultiRMSE: 0.21467107242976863\n",
      "Mean MultiRMSE: 0.2147\n",
      "Std: 0.0\n"
     ]
    }
   ],
   "source": [
    "fit_time, _ = strategy.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: less then Day (Hour, Min, Sec, etc); period: 900.0 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>12.333083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>12.13246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>12.207673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>3.671136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>3.653514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>3.679937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>4.554753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>4.518773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>4.512365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>1.500343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>1.501834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>1.501802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>7.897749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>7.73234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>7.657212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>1.71692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>1.704306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>1.695499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-26 20:00:00</td>\n",
       "      <td>9.764208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-26 20:15:00</td>\n",
       "      <td>9.764208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-26 20:30:00</td>\n",
       "      <td>9.791838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                date      value\n",
       "0   0 2018-06-26 20:00:00  12.333083\n",
       "1   0 2018-06-26 20:15:00   12.13246\n",
       "2   0 2018-06-26 20:30:00  12.207673\n",
       "3   1 2018-06-26 20:00:00   3.671136\n",
       "4   1 2018-06-26 20:15:00   3.653514\n",
       "5   1 2018-06-26 20:30:00   3.679937\n",
       "6   2 2018-06-26 20:00:00   4.554753\n",
       "7   2 2018-06-26 20:15:00   4.518773\n",
       "8   2 2018-06-26 20:30:00   4.512365\n",
       "9   3 2018-06-26 20:00:00   1.500343\n",
       "10  3 2018-06-26 20:15:00   1.501834\n",
       "11  3 2018-06-26 20:30:00   1.501802\n",
       "12  4 2018-06-26 20:00:00   7.897749\n",
       "13  4 2018-06-26 20:15:00    7.73234\n",
       "14  4 2018-06-26 20:30:00   7.657212\n",
       "15  5 2018-06-26 20:00:00    1.71692\n",
       "16  5 2018-06-26 20:15:00   1.704306\n",
       "17  5 2018-06-26 20:30:00   1.695499\n",
       "18  6 2018-06-26 20:00:00   9.764208\n",
       "19  6 2018-06-26 20:15:00   9.764208\n",
       "20  6 2018-06-26 20:30:00   9.791838"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_time, current_pred = strategy.predict(dataset)\n",
    "current_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best_preds, best_strat = blender.fit_predict(strtgs, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(strategy.models[0].scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = []\n",
    "#for model in strategy2.models:\n",
    "#    score = np.mean(model.scores)\n",
    "#    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_time, _ = strategy.fit(dataset)\n",
    "#fit_time2, _ = strategy2.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast_time, current_pred = strategy.predict(dataset)\n",
    "\n",
    "# Blender test\n",
    "#forecast_time2, current_pred2 = strategy2.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_preds = blender.fit_predict([current_pred.value, current_pred2.value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest validation of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids, test, pred, fit_time, forecast_time = strategy.back_test(dataset, cv=1)\n",
    "\n",
    "# Blender test\n",
    "#ids2, test2, pred2, fit_time2, forecast_time2 = strategy2.back_test(dataset, cv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic preds\n",
    "#pred3 = [el/2 for el in pred2]\n",
    "#pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean blender\n",
    "#final_preds = blender.fit_predict([pred, pred2, pred3])\n",
    "#final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(pred[0]+pred2[0]+pred3[0])/3 == final_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_results(cv=1, regime=\"global\", y_true=test, y_pred=pred, ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with raw time series' granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series come in different granularities, from hourly and daily time series to more complex ones such as the end of each quarter.\n",
    "\n",
    "If the rows do not contain segments that are too short (that are shorter than history + horizon), then `tsururu` will try to extract the row granularity on its own. We currently support the following types:\n",
    "\n",
    "- Yearly (and YearlyEnd)\n",
    "- Quarterly (and Quarterly)\n",
    "- Monthly (and MonthlyEnd)\n",
    "- Weekly\n",
    "- Daily\n",
    "- Hourly\n",
    "- Minlutely\n",
    "- Secondly\n",
    "- Microsecondly\n",
    "\n",
    "There is also support for compound granularities (10 days, 15 minutes, 32 seconds, etc.). The correctness of the selected granularity can be checked from the output after the `Dataset` class has been created.\n",
    "\n",
    "However, there are tricky situations (e.g. 28 days) where the monthly granularity may be guessed incorrectly. Therefore, it is possible to set your own granularity using the `pd.DateOffset` class or related classes from `pandas.tseries.offsets`, which must be fed as `delta` parameter into the `Dataset` class. Then the time column will be processed according to the user's settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a time series where each point is exactly __28 daily points away__ from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_2 = \"datasets/global/simulated_data_to_check_28D.csv\"\n",
    "\n",
    "# Configure the features settings\n",
    "dataset_params_2 = {\n",
    "    \"target\": {\n",
    "        \"columns\": [\"value\"],\n",
    "        \"type\": \"continious\",\n",
    "    },\n",
    "    \"date\": {\n",
    "        \"columns\": [\"date\"],\n",
    "        \"type\": \"datetime\",\n",
    "    },\n",
    "    \"id\": {\n",
    "        \"columns\": [\"id\"],\n",
    "        \"type\": \"categorical\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: Month; period: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = TSDataset(\n",
    "    data=pd.read_csv(df_path_2),\n",
    "    columns_params=dataset_params_2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the frequency of the series is incorrectly defined as monthly. Let's try to pass the `delta` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom OffSet: <DateOffset: days=28>\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = TSDataset(\n",
    "    data=pd.read_csv(df_path_2),\n",
    "    columns_params=dataset_params_2,\n",
    "    delta=pd.DateOffset(days=28),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's all detected correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
